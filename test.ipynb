{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cntk as ct\n",
    "\n",
    "from src.ferplus import FERPlusReader, FERPlusParameters\n",
    "from src.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_func(training_mode, prediction, target):\n",
    "    '''\n",
    "    We use cross entropy in most mode, except for the multi-label mode, which require treating\n",
    "    multiple labels exactly the same.\n",
    "    '''\n",
    "    train_loss = None\n",
    "    if training_mode == 'majority' or training_mode == 'probability' or training_mode == 'crossentropy': \n",
    "        # Cross Entropy.\n",
    "        train_loss = ct.negate(ct.reduce_sum(ct.element_times(target, ct.log(prediction)), axis=-1))\n",
    "    elif training_mode == 'multi_target':\n",
    "        train_loss = ct.negate(ct.log(ct.reduce_max(ct.element_times(target, prediction), axis=-1)))\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parametros\n",
    "model_name='VGG13'\n",
    "\n",
    "training_mode = \"crossentropy\"\n",
    "base_folder = 'data'\n",
    "\n",
    "test_folders  = ['FER2013Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# folders\n",
    "output_model_path   = os.path.join(base_folder, R'models')\n",
    "output_model_folder = os.path.join(output_model_path, model_name + '_' + training_mode)\n",
    "\n",
    "if not os.path.exists(output_model_folder):\n",
    "    os.makedirs(output_model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotion_table = {'neutral'  : 0, \n",
    "                 'happiness': 1, \n",
    "                 'surprise' : 2, \n",
    "                 'sadness'  : 3, \n",
    "                 'anger'    : 4, \n",
    "                 'disgust'  : 5, \n",
    "                 'fear'     : 6, \n",
    "                 'contempt' : 7}\n",
    "\n",
    "num_classes = len(emotion_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# leitura do modelo\n",
    "model = build_model(num_classes, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the input variables.\n",
    "input_var = ct.input((1, model.input_height, model.input_width), np.float32)\n",
    "label_var = ct.input((num_classes), np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training_mode interfere nos labels, fazendo com que seja 0 e 1 ou entre 0 e 1.\n",
    "# por algum motivo, no test_and_val_params ele está estatico em 'majatory'\n",
    "# test_and_val_params = FERPlusParameters(num_classes, model.input_height, model.input_width, training_mode, True)\n",
    "test_and_val_params = FERPlusParameters(num_classes, model.input_height, model.input_width, \"majority\", True)\n",
    "test_data_reader = FERPlusReader.create(base_folder, test_folders, \"label.csv\", test_and_val_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch_size = test_data_reader.size()\n",
    "minibatch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the probalistic output of the model.\n",
    "z    = model.model(input_var)\n",
    "pred = ct.softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training config\n",
    "lr_per_minibatch       = [model.learning_rate]*20 + [model.learning_rate / 2.0]*20 + [model.learning_rate / 10.0]\n",
    "mm_time_constant       = -minibatch_size/np.log(0.9)\n",
    "lr_schedule            = ct.learning_rate_schedule(lr_per_minibatch, unit=ct.UnitType.minibatch, epoch_size=epoch_size)\n",
    "mm_schedule            = ct.momentum_as_time_constant_schedule(mm_time_constant)\n",
    "\n",
    "# loss and error cost\n",
    "train_loss = cost_func(training_mode, pred, label_var)\n",
    "pe         = ct.classification_error(z, label_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct the trainer\n",
    "learner = ct.momentum_sgd(z.parameters, lr_schedule, mm_schedule)\n",
    "trainer = ct.Trainer(z, (train_loss, pe), learner)\n",
    "trainer.total_number_of_samples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2766753"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch = 98\n",
    "trainer.restore_from_checkpoint(os.path.join(output_model_folder, \"model_{}\".format(best_epoch)))\n",
    "trainer.total_number_of_samples_seen"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_predicts = []\n",
    "true_labels = []\n",
    "while test_data_reader.has_more():\n",
    "    images, labels, current_batch_size = test_data_reader.next_minibatch(minibatch_size)\n",
    "    true_labels.append(labels)\n",
    "    y_predicts.append <- trainer.model.eval() # ver parametros e retorno do método"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
