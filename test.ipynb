{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cntk as ct\n",
    "\n",
    "from src.ferplus import FERPlusReader, FERPlusParameters\n",
    "from src.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_func(training_mode, prediction, target):\n",
    "    '''\n",
    "    We use cross entropy in most mode, except for the multi-label mode, which require treating\n",
    "    multiple labels exactly the same.\n",
    "    '''\n",
    "    train_loss = None\n",
    "    if training_mode == 'majority' or training_mode == 'probability' or training_mode == 'crossentropy': \n",
    "        # Cross Entropy.\n",
    "        train_loss = ct.negate(ct.reduce_sum(ct.element_times(target, ct.log(prediction)), axis=-1))\n",
    "    elif training_mode == 'multi_target':\n",
    "        train_loss = ct.negate(ct.log(ct.reduce_max(ct.element_times(target, prediction), axis=-1)))\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emotion_table = {'neutral'  : 0, \n",
    "                 'happiness': 1, \n",
    "                 'surprise' : 2, \n",
    "                 'sadness'  : 3, \n",
    "                 'anger'    : 4, \n",
    "                 'disgust'  : 5, \n",
    "                 'fear'     : 6, \n",
    "                 'contempt' : 7}\n",
    "\n",
    "emotion_labels = sorted(emotion_table, key=emotion_table.get)\n",
    "\n",
    "num_classes = len(emotion_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## parametros\n",
    "model_name='VGG13'\n",
    "\n",
    "base_folder = 'data'\n",
    "test_folders  = ['FER2013Test']\n",
    "\n",
    "# training_mode and best_epoch\n",
    "tmbe = [(\"majority\",80), (\"probability\",78), (\"crossentropy\",98), (\"multi_target\",89)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/models/VGG13_majority/model_80\n",
      "trainer.total_number_of_samples_seen:  2028645\n",
      "test_data_reader.size:  3137\n",
      "some example of data; probabilistic; deterministic\n",
      "y_true[2]:  [ 0.  0.  0.  0.  1.  0.  0.  0.] ; 4\n",
      "y_pred[2]:  [ -6.02  -2.97   0.87  -4.37  12.58   4.58  -0.14  -2.42] ; 4\n",
      "save y_true and y_pred in  data/tests/VGG13_majority/test_80.npz\n",
      "\n",
      "\n",
      "\n",
      "data/models/VGG13_probability/model_78\n",
      "trainer.total_number_of_samples_seen:  2207813\n",
      "test_data_reader.size:  3137\n",
      "some example of data; probabilistic; deterministic\n",
      "y_true[2]:  [ 0.  0.  0.  0.  1.  0.  0.  0.] ; 4\n",
      "y_pred[2]:  [-2.66 -0.12  2.11 -2.92  7.01 -0.15  0.6  -3.82] ; 4\n",
      "save y_true and y_pred in  data/tests/VGG13_probability/test_78.npz\n",
      "\n",
      "\n",
      "\n",
      "data/models/VGG13_crossentropy/model_98\n",
      "trainer.total_number_of_samples_seen:  2766753\n",
      "test_data_reader.size:  3137\n",
      "some example of data; probabilistic; deterministic\n",
      "y_true[2]:  [ 0.  0.  0.  0.  1.  0.  0.  0.] ; 4\n",
      "y_pred[2]:  [-2.72 -1.01  1.98 -3.4   8.08  0.79  0.35 -3.75] ; 4\n",
      "save y_true and y_pred in  data/tests/VGG13_crossentropy/test_98.npz\n",
      "\n",
      "\n",
      "\n",
      "data/models/VGG13_multi_target/model_89\n",
      "trainer.total_number_of_samples_seen:  2490030\n",
      "test_data_reader.size:  3137\n",
      "some example of data; probabilistic; deterministic\n",
      "y_true[2]:  [ 0.  0.  0.  0.  1.  0.  0.  0.] ; 4\n",
      "y_pred[2]:  [ -8.72   0.87   0.49  -2.75  15.25   5.    -0.9   -5.29] ; 4\n",
      "save y_true and y_pred in  data/tests/VGG13_multi_target/test_89.npz\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for training_mode, best_epoch in tmbe:\n",
    "    ## folders models\n",
    "    output_model_path   = os.path.join(base_folder, R'models')\n",
    "    output_model_folder = os.path.join(output_model_path, model_name + '_' + training_mode)\n",
    "\n",
    "    if not os.path.exists(output_model_folder):\n",
    "        os.makedirs(output_model_folder)\n",
    "        \n",
    "    ## folders tests\n",
    "    output_test_path   = os.path.join(base_folder, R'tests')\n",
    "    output_test_folder = os.path.join(output_test_path, model_name + '_' + training_mode)\n",
    "\n",
    "    if not os.path.exists(output_test_folder):\n",
    "        os.makedirs(output_test_folder)\n",
    "        \n",
    "    ## leitura do modelo\n",
    "    model = build_model(num_classes, model_name)\n",
    "    \n",
    "    ## set the input variables.\n",
    "    input_var = ct.input((1, model.input_height, model.input_width), np.float32)\n",
    "    label_var = ct.input((num_classes), np.float32)\n",
    "    \n",
    "    # params and reader FERPlus (in original work, training_mode is static set to \"majority\" in test_val_params. We kept this until understand why.)\n",
    "    # test_and_val_params = FERPlusParameters(num_classes, model.input_height, model.input_width, training_mode, determinisitc=True, shuffle=False)\n",
    "    test_and_val_params = FERPlusParameters(num_classes, model.input_height, model.input_width, \"majority\", determinisitc=True, shuffle=False)\n",
    "    test_data_reader = FERPlusReader.create(base_folder, test_folders, \"label.csv\", test_and_val_params)\n",
    "    \n",
    "    epoch_size = test_data_reader.size()\n",
    "    minibatch_size = 32\n",
    "    \n",
    "    # get the probalistic output of the model.\n",
    "    z    = model.model(input_var)\n",
    "    pred = ct.softmax(z)\n",
    "    \n",
    "    # Training config\n",
    "    lr_per_minibatch       = [model.learning_rate]*20 + [model.learning_rate / 2.0]*20 + [model.learning_rate / 10.0]\n",
    "    mm_time_constant       = -minibatch_size/np.log(0.9)\n",
    "    lr_schedule            = ct.learning_rate_schedule(lr_per_minibatch, unit=ct.UnitType.minibatch, epoch_size=epoch_size)\n",
    "    mm_schedule            = ct.momentum_as_time_constant_schedule(mm_time_constant)\n",
    "\n",
    "    # loss and error cost\n",
    "    train_loss = cost_func(training_mode, pred, label_var)\n",
    "    pe         = ct.classification_error(z, label_var)    \n",
    "    \n",
    "    # construct the trainer\n",
    "    learner = ct.momentum_sgd(z.parameters, lr_schedule, mm_schedule)\n",
    "    trainer = ct.Trainer(z, (train_loss, pe), learner)\n",
    "    \n",
    "    # restore trained model\n",
    "    print(os.path.join(output_model_folder, \"model_{}\".format(best_epoch)))\n",
    "    trainer.restore_from_checkpoint(os.path.join(output_model_folder, \"model_{}\".format(best_epoch)))\n",
    "    print('trainer.total_number_of_samples_seen: ', trainer.total_number_of_samples_seen)\n",
    "    \n",
    "    print('test_data_reader.size: ',test_data_reader.size())\n",
    "    # init predictions\n",
    "    y_true_batch = []\n",
    "    y_pred_batch = []\n",
    "\n",
    "    while test_data_reader.has_more():\n",
    "        images, labels, current_batch_size = test_data_reader.next_minibatch(minibatch_size)\n",
    "        y_true_batch.append(labels)\n",
    "        y_pred_batch.append(trainer.model.eval({input_var: images}))\n",
    "        \n",
    "    # concatene all minibatchs\n",
    "    y_true = np.concatenate(y_true_batch, axis=0)\n",
    "    y_pred = np.concatenate(y_pred_batch, axis=0)\n",
    "    \n",
    "    np.set_printoptions(precision=2)\n",
    "    print('some example of data; probabilistic; deterministic')\n",
    "    print('y_true[2]: ',y_true[2],';',y_true[2].argmax())\n",
    "    print('y_pred[2]: ',y_pred[2],';',y_pred[2].argmax())\n",
    "\n",
    "    np.savez_compressed(os.path.join(output_test_folder, \"test_{}.npz\".format(best_epoch)), y_true=y_true, y_pred=y_pred)\n",
    "    print('save y_true and y_pred in ', os.path.join(output_test_folder, \"test_{}.npz\".format(best_epoch)))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
